user,search
splunkmonitoring,"search index=""summary_indexers"" | timechart partial=f span=30m per_second(kb) as KBps | eval marker = ""today"" | eval _time = _time+1800 | append [search index=""summary_indexers"" earliest=-7d@d-30m latest=-6d@d-30m | timechart span=30m per_second(kb) as KBps | eval marker = ""this day last week"" | eval _time = _time+86400*7+1800] | timechart median(KBps) by marker"
splunkmonitoring,"search index=""summary_indexers"" | timechart partial=f span=30m per_second(kb) as KBps | addinfo | eval marker = if(_time < info_min_time + 7*86400, ""last week"", ""this week"") | eval _time = if(_time < info_min_time + 7*86400, _time + 7*86400+1800, _time+1800) | chart median(KBps) by _time marker"
splunkmonitoring,"search index=""summary_forwarders"" | timechart partial=f span=30m dc(guid) as distcount | eval marker = ""today"" | eval _time = _time+1800 | append [search earliest=-7d@d-30m latest=-6d@d-30m index=""summary_forwarders"" | timechart span=30m dc(guid) as distcount| eval marker = ""this day last week"" | eval _time = _time+86400*7+1800] | timechart median(distcount) by marker |  eval today=if(_time>now()-60,null(), today)"
splunkmonitoring,"search index=""summary_indexers"" | eval _time = _time + 1800 | stats max(_time) as _time sum(kb) as KB first(avg_age) as avg_age first(parseQ_percentage) as parseQ_percentage first(indexQ_percentage) as indexQ_percentage by my_splunk_server |rename my_splunk_server as splunk_server | join type=outer splunk_server [search earliest=-30m latest=now  search index=""_internal"" source=""*metrics.log"" group=per_index_thruput series!=""_*"" | stats max(_time) as time1 sum(kb) as kb by splunk_server | join type=""outer"" splunk_server [ search earliest=-30m latest=now    search index=""_internal"" source=""*metrics.log"" group=queue name=parsingqueue | chart perc95(current_size_kb) as p95sz, max(max_size_kb) as maxsz by splunk_server | eval percentage=p95sz*100/maxsz | rename percentage as parseQ_percentage | appendcols [search  search index=""_internal"" source=""*metrics.log"" group=queue name=indexqueue | chart perc95(current_size_kb) as p95sz, max(max_size_kb) as maxsz by splunk_server | eval percentage=p95sz*100/maxsz | rename percentage as indexQ_percentage] | appendcols [search  search index=_internal group=per_sourcetype_thruput series=access_* | eval latency=avg_age*ev | stats sum(latency) as latency sum(ev) as events by splunk_server | fillnull latency events | eval avg_age=latency/events | fields avg_age] | fields splunk_server avg_age parseQ_percentage indexQ_percentage | fillnull avg_age] | addinfo |eval mystatus = if(kb==0, ""idle"", if(parseQ_percentage>50, ""overloaded"", if(indexQ_percentage>50,""overloaded"",""normal"")))] | eval _time = if(time1>_time, time1, _time) | addinfo | eval status = if(isnull(mystatus), ""dead"",mystatus) | search status = ""idle"" | fields splunk_server KB status | rename splunk_server as ""Splunk Server"" KB as ""Total KB"" status as ""Current Status"""
splunkmonitoring,"search index=""summary_indexers"" | eval _time = _time + 1800 | stats max(_time) as _time sum(kb) as KB first(avg_age) as avg_age first(parseQ_percentage) as parseQ_percentage first(indexQ_percentage) as indexQ_percentage by my_splunk_server |rename my_splunk_server as splunk_server | join type=outer splunk_server [search earliest=-30m latest=now  search index=""_internal"" source=""*metrics.log"" group=per_index_thruput series!=""_*"" | stats max(_time) as time1 sum(kb) as kb by splunk_server | join type=""outer"" splunk_server [ search earliest=-30m latest=now    search index=""_internal"" source=""*metrics.log"" group=queue name=parsingqueue | chart perc95(current_size_kb) as p95sz, max(max_size_kb) as maxsz by splunk_server | eval percentage=p95sz*100/maxsz | rename percentage as parseQ_percentage | appendcols [search  search index=""_internal"" source=""*metrics.log"" group=queue name=indexqueue | chart perc95(current_size_kb) as p95sz, max(max_size_kb) as maxsz by splunk_server | eval percentage=p95sz*100/maxsz | rename percentage as indexQ_percentage] | appendcols [search  search index=_internal group=per_sourcetype_thruput series=access_* | eval latency=avg_age*ev | stats sum(latency) as latency sum(ev) as events by splunk_server | fillnull latency events | eval avg_age=latency/events | fields avg_age] | fields splunk_server avg_age parseQ_percentage indexQ_percentage | fillnull avg_age] | addinfo |eval mystatus = if(kb==0, ""idle"", if(parseQ_percentage>50, ""overloaded"", if(indexQ_percentage>50,""overloaded"",""normal"")))] | eval _time = if(time1>_time, time1, _time) | addinfo | eval status = if(isnull(mystatus), ""dead"",mystatus) | search status=""overloaded"" | fields splunk_server avg_age parseQ_percentage indexQ_percentage status | rename splunk_server as ""Splunk Server""  avg_age as ""Average Latency (in Seconds)"" parseQ_percentage as ""Parsing Queue 95th Percentile As Fraction of Max Queue Size"" indexQ_percentage as ""Index Queue 95th Percentile As Fraction of Max Queue Size"" status as ""Current Status"""
splunkmonitoring,"search index=""summary_forwarders"" | eval _time = _time + 1800 | stats first(sourceIp) as sourceIp first(connectionType) as connectionType first(sourcePort) as sourcePort first(build) as build first(version) as version first(os) as os first(arch) as arch max(lastConnected) as lastConnected max(lastReceived) as lastReceived sum(kb) as KB first(avg_eps) as eps by sourceHost guid | join type=outer guid [search earliest=-30m latest=now  search index=""_internal"" source=""*metrics.log"" group=tcpin_connections | eval sourceHost=if(isnull(hostname), sourceHost,hostname) | eval connectionType=case(fwdType==""uf"",""Universal Forwarder"", fwdType==""lwf"", ""Light Weight Forwarder"",fwdType==""full"", ""Splunk Indexed"", connectionType==""cooked"" or connectionType==""cookedSSL"",""Splunk Forwarder"", connectionType==""raw"" or connectionType==""rawSSL"",""Legacy Forwarder"")| eval build=if(isnull(build),""n/a"",build) | eval version=if(isnull(version),""pre 4.2"",version) | eval guid=if(isnull(guid),sourceHost,guid) | eval os=if(isnull(os),""n/a"",os)| eval arch=if(isnull(arch),""n/a"",arch) | eval my_splunk_server = splunk_server | fields connectionType sourceIp sourceHost sourcePort destPort kb tcp_eps tcp_Kprocessed tcp_KBps my_splunk_server build version os arch guid | eval lastReceived = if(kb>0, _time, null) | stats first(sourceIp) as sourceIp first(connectionType) as connectionType first(sourcePort) as sourcePort first(build) as build first(version) as version first(os) as os first(arch) as arch  max(_time) as lastConnected1 max(lastReceived) as lastReceived1 sum(kb) as kb by sourceHost guid | addinfo | eval mystatus = if(lastConnected>(lastReceived+300) or kb==0,""quiet"",""dunno"") ] | eval lastConnected=if(lastConnected1>lastConnected, lastConnected1, lastConnected) | eval lastReceived=if(lastReceived1>lastReceived, lastReceived1, lastReceived) |  addinfo | eval status = if(isnull(KB) or lastConnected<(info_max_time-900),""missing"",if(mystatus=""quiet"",""quiet"",""active"")) | convert ctime(lastConnected) ctime(lastReceived) ctime(info_max_time) | search status=""missing"" | sort - lastConnected | fields sourceHost sourceIp connectionType lastConnected status | rename sourceHost as ""Forwarder"" sourceIp as ""Source IP"" connectionType as ""Forwarder Type"" lastConnected as ""Last Connected"" status as ""Current Status""  | fieldformat ""Last Connected""=strftime('Last Connected', ""%D %H:%M:%S %p"")"
splunkmonitoring,"search index=""summary_forwarders"" | eval _time = _time + 1800 | stats first(sourceIp) as sourceIp first(connectionType) as connectionType first(sourcePort) as sourcePort first(build) as build first(version) as version first(os) as os first(arch) as arch max(lastConnected) as lastConnected max(lastReceived) as lastReceived sum(kb) as KB first(avg_eps) as eps by sourceHost guid | join type=outer guid [search earliest=-30m latest=now  search index=""_internal"" source=""*metrics.log"" group=tcpin_connections | eval sourceHost=if(isnull(hostname), sourceHost,hostname) | eval connectionType=case(fwdType==""uf"",""Universal Forwarder"", fwdType==""lwf"", ""Light Weight Forwarder"",fwdType==""full"", ""Splunk Indexed"", connectionType==""cooked"" or connectionType==""cookedSSL"",""Splunk Forwarder"", connectionType==""raw"" or connectionType==""rawSSL"",""Legacy Forwarder"")| eval build=if(isnull(build),""n/a"",build) | eval version=if(isnull(version),""pre 4.2"",version) | eval guid=if(isnull(guid),sourceHost,guid) | eval os=if(isnull(os),""n/a"",os)| eval arch=if(isnull(arch),""n/a"",arch) | eval my_splunk_server = splunk_server | fields connectionType sourceIp sourceHost sourcePort destPort kb tcp_eps tcp_Kprocessed tcp_KBps my_splunk_server build version os arch guid | eval lastReceived = if(kb>0, _time, null) | stats first(sourceIp) as sourceIp first(connectionType) as connectionType first(sourcePort) as sourcePort first(build) as build first(version) as version first(os) as os first(arch) as arch  max(_time) as lastConnected1 max(lastReceived) as lastReceived1 sum(kb) as kb by sourceHost guid | addinfo | eval mystatus = if(lastConnected>(lastReceived+300) or kb==0,""quiet"",""dunno"") ] | eval lastConnected=if(lastConnected1>lastConnected, lastConnected1, lastConnected) | eval lastReceived=if(lastReceived1>lastReceived, lastReceived1, lastReceived) |  addinfo | eval status = if(isnull(KB) or lastConnected<(info_max_time-900),""missing"",if(mystatus=""quiet"",""quiet"",""active"")) | convert ctime(lastConnected) ctime(lastReceived) ctime(info_max_time) | search status=""quiet"" | sort - lastReceived | eval eps = round(eps,4) | fields sourceHost sourceIp connectionType lastConnected lastReceived KB eps status | rename sourceHost as ""Forwarder"" sourceIp as ""Source IP"" connectionType as ""Forwarder Type"" lastConnected as ""Last Connected"" lastReceived as ""Last Data Received"" KB as ""Total KB"" eps as ""Average Events Per Second"" status as ""Current Status""  | fieldformat ""Last Connected""=strftime('Last Connected', ""%D %H:%M:%S %p"")  | fieldformat ""Last Data Received""=strftime('Last Data Received', ""%D %H:%M:%S %p"")"
splunkmonitoring,"search index=""_internal"" source=""*metrics.log"" group=tcpin_connections | eval sourceHost=if(isnull(hostname), sourceHost,hostname) | eval connectionType=case(fwdType==""uf"",""Universal Forwarder"", fwdType==""lwf"", ""Light Weight Forwarder"",fwdType==""full"", ""Splunk Indexed"", connectionType==""cooked"" or connectionType==""cookedSSL"",""Splunk Forwarder"", connectionType==""raw"" or connectionType==""rawSSL"",""Legacy Forwarder"")| eval build=if(isnull(build),""n/a"",build) | eval version=if(isnull(version),""pre 4.2"",version) | eval guid=if(isnull(guid),sourceHost,guid) | eval os=if(isnull(os),""n/a"",os)| eval arch=if(isnull(arch),""n/a"",arch) | eval my_splunk_server = splunk_server | fields connectionType sourceIp sourceHost sourcePort destPort kb tcp_eps tcp_Kprocessed tcp_KBps my_splunk_server build version os arch guid |  stats values(sourceHost) as sourceHost values(connectionType) as connectionType values(sourcePort) as sourcePort values(destPort) as destPort sum(kb) avg(tcp_eps) avg(tcp_Kprocessed) avg(tcp_KBps) avg(kb) as avg_kb_today by sourceIp  | join sourceIp type=outer [search earliest=-169h@h latest=-168h@h  search index=""_internal"" source=""*metrics.log"" group=tcpin_connections | eval sourceHost=if(isnull(hostname), sourceHost,hostname) | eval connectionType=case(fwdType==""uf"",""Universal Forwarder"", fwdType==""lwf"", ""Light Weight Forwarder"",fwdType==""full"", ""Splunk Indexed"", connectionType==""cooked"" or connectionType==""cookedSSL"",""Splunk Forwarder"", connectionType==""raw"" or connectionType==""rawSSL"",""Legacy Forwarder"")| eval build=if(isnull(build),""n/a"",build) | eval version=if(isnull(version),""pre 4.2"",version) | eval guid=if(isnull(guid),sourceHost,guid) | eval os=if(isnull(os),""n/a"",os)| eval arch=if(isnull(arch),""n/a"",arch) | eval my_splunk_server = splunk_server | fields connectionType sourceIp sourceHost sourcePort destPort kb tcp_eps tcp_Kprocessed tcp_KBps my_splunk_server build version os arch guid| stats avg(kb) as avg_kb_last_week by sourceIp] | fillnull avg_kb_today avg_kb_last_week | appendcols [search  search earliest=-1h@h latest=now  search index=""_internal"" source=""*metrics.log"" group=per_index_thruput series!=""_*"" | stats avg(kb) as indexer_avg_kb_today | join splunk_server type=outer [search earliest=-169h@h latest=-168h@h  search index=""_internal"" source=""*metrics.log"" group=per_index_thruput series!=""_*""| stats avg(kb) as indexer_avg_kb_last_week count | fillnull indexer_avg_kb_last_week | fields indexer_avg_kb_last_week] | fillnull indexer_avg_kb_today | eval indexer_ratio=indexer_avg_kb_today/indexer_avg_kb_last_week | fields indexer_ratio] | streamstats first(indexer_ratio) as indexer_ratio |  where indexer_ratio*.5*avg_kb_last_week > avg_kb_today | eval kb_diff = abs(round(avg_kb_last_week - avg_kb_today, 4)) | eval kb_diff_perc = round(100*kb_diff/avg_kb_last_week, 4) | eval avg_kb_last_week = round(avg_kb_last_week, 4) | eval avg_kb_today = round(avg_kb_today, 4) |  fields sourceHost connectionType avg_kb_last_week avg_kb_today kb_diff kb_diff_perc | rename sourceHost as ""Forwarder"" avg_kb_last_week as ""Average KBps Last Week"" avg_kb_today as ""Average KBps Today"" connectionType as ""Forwarder Type""  kb_diff as ""KBps Difference from Last Week"" kb_diff_perc as ""Percentage Difference"""
splunkmonitoring,"search index=""_internal"" source=""*metrics.log"" group=tcpin_connections | eval sourceHost=if(isnull(hostname), sourceHost,hostname) | eval connectionType=case(fwdType==""uf"",""Universal Forwarder"", fwdType==""lwf"", ""Light Weight Forwarder"",fwdType==""full"", ""Splunk Indexed"", connectionType==""cooked"" or connectionType==""cookedSSL"",""Splunk Forwarder"", connectionType==""raw"" or connectionType==""rawSSL"",""Legacy Forwarder"")| eval build=if(isnull(build),""n/a"",build) | eval version=if(isnull(version),""pre 4.2"",version) | eval guid=if(isnull(guid),sourceHost,guid) | eval os=if(isnull(os),""n/a"",os)| eval arch=if(isnull(arch),""n/a"",arch) | eval my_splunk_server = splunk_server | fields connectionType sourceIp sourceHost sourcePort destPort kb tcp_eps tcp_Kprocessed tcp_KBps my_splunk_server build version os arch guid |  stats values(sourceHost) as sourceHost values(connectionType) as connectionType values(sourcePort) as sourcePort values(destPort) as destPort sum(kb) avg(tcp_eps) avg(tcp_Kprocessed) avg(tcp_KBps) avg(kb) as avg_kb_today by sourceIp  | join sourceIp type=outer [search earliest=-169h@h latest=-168h@h  search index=""_internal"" source=""*metrics.log"" group=tcpin_connections | eval sourceHost=if(isnull(hostname), sourceHost,hostname) | eval connectionType=case(fwdType==""uf"",""Universal Forwarder"", fwdType==""lwf"", ""Light Weight Forwarder"",fwdType==""full"", ""Splunk Indexed"", connectionType==""cooked"" or connectionType==""cookedSSL"",""Splunk Forwarder"", connectionType==""raw"" or connectionType==""rawSSL"",""Legacy Forwarder"")| eval build=if(isnull(build),""n/a"",build) | eval version=if(isnull(version),""pre 4.2"",version) | eval guid=if(isnull(guid),sourceHost,guid) | eval os=if(isnull(os),""n/a"",os)| eval arch=if(isnull(arch),""n/a"",arch) | eval my_splunk_server = splunk_server | fields connectionType sourceIp sourceHost sourcePort destPort kb tcp_eps tcp_Kprocessed tcp_KBps my_splunk_server build version os arch guid| stats avg(kb) as avg_kb_last_week by sourceIp] | fillnull avg_kb_today avg_kb_last_week | appendcols [search  search earliest=-1h@h latest=now  search index=""_internal"" source=""*metrics.log"" group=per_index_thruput series!=""_*"" | stats avg(kb) as indexer_avg_kb_today | join splunk_server type=outer [search earliest=-169h@h latest=-168h@h  search index=""_internal"" source=""*metrics.log"" group=per_index_thruput series!=""_*""| stats avg(kb) as indexer_avg_kb_last_week count | fillnull indexer_avg_kb_last_week | fields indexer_avg_kb_last_week] | fillnull indexer_avg_kb_today | eval indexer_ratio=indexer_avg_kb_today/indexer_avg_kb_last_week | fields indexer_ratio] | streamstats first(indexer_ratio) as indexer_ratio |  where indexer_ratio*avg_kb_last_week < .5*avg_kb_today | eval kb_diff = abs(round(avg_kb_last_week - avg_kb_today, 4)) | eval kb_diff_perc = round(100*kb_diff/avg_kb_last_week, 4) | eval avg_kb_last_week = round(avg_kb_last_week, 4) | eval avg_kb_today = round(avg_kb_today, 4) |  fields sourceHost connectionType avg_kb_last_week avg_kb_today kb_diff kb_diff_perc | rename sourceHost as ""Forwarder"" avg_kb_last_week as ""Average KBps Last Week"" avg_kb_today as ""Average KBps Today"" connectionType as ""Forwarder Type""  kb_diff as ""KBps Difference from Last Week"" kb_diff_perc as ""Percentage Difference"""
splunkmonitoring,"search index=""summary_forwarders"" | eval _time = _time + 1800 | stats first(sourceIp) as sourceIp first(connectionType) as connectionType first(sourcePort) as sourcePort first(build) as build first(version) as version first(os) as os first(arch) as arch max(lastConnected) as lastConnected max(lastReceived) as lastReceived sum(kb) as KB first(avg_eps) as eps by sourceHost guid | join type=outer guid [search earliest=-30m latest=now  search index=""_internal"" source=""*metrics.log"" group=tcpin_connections | eval sourceHost=if(isnull(hostname), sourceHost,hostname) | eval connectionType=case(fwdType==""uf"",""Universal Forwarder"", fwdType==""lwf"", ""Light Weight Forwarder"",fwdType==""full"", ""Splunk Indexed"", connectionType==""cooked"" or connectionType==""cookedSSL"",""Splunk Forwarder"", connectionType==""raw"" or connectionType==""rawSSL"",""Legacy Forwarder"")| eval build=if(isnull(build),""n/a"",build) | eval version=if(isnull(version),""pre 4.2"",version) | eval guid=if(isnull(guid),sourceHost,guid) | eval os=if(isnull(os),""n/a"",os)| eval arch=if(isnull(arch),""n/a"",arch) | eval my_splunk_server = splunk_server | fields connectionType sourceIp sourceHost sourcePort destPort kb tcp_eps tcp_Kprocessed tcp_KBps my_splunk_server build version os arch guid | eval lastReceived = if(kb>0, _time, null) | stats first(sourceIp) as sourceIp first(connectionType) as connectionType first(sourcePort) as sourcePort first(build) as build first(version) as version first(os) as os first(arch) as arch  max(_time) as lastConnected1 max(lastReceived) as lastReceived1 sum(kb) as kb by sourceHost guid | addinfo | eval mystatus = if(lastConnected>(lastReceived+300) or kb==0,""quiet"",""dunno"") ] | eval lastConnected=if(lastConnected1>lastConnected, lastConnected1, lastConnected) | eval lastReceived=if(lastReceived1>lastReceived, lastReceived1, lastReceived) |  addinfo | eval status = if(isnull(KB) or lastConnected<(info_max_time-900),""missing"",if(mystatus=""quiet"",""quiet"",""active"")) | convert ctime(lastConnected) ctime(lastReceived) ctime(info_max_time)"
splunkmonitoring,"search index=""_internal"" source=""*metrics.log"" group=tcpin_connections | eval sourceHost=if(isnull(hostname), sourceHost,hostname) | eval connectionType=case(fwdType==""uf"",""Universal Forwarder"", fwdType==""lwf"", ""Light Weight Forwarder"",fwdType==""full"", ""Splunk Indexed"", connectionType==""cooked"" or connectionType==""cookedSSL"",""Splunk Forwarder"", connectionType==""raw"" or connectionType==""rawSSL"",""Legacy Forwarder"")| eval build=if(isnull(build),""n/a"",build) | eval version=if(isnull(version),""pre 4.2"",version) | eval guid=if(isnull(guid),sourceHost,guid) | eval os=if(isnull(os),""n/a"",os)| eval arch=if(isnull(arch),""n/a"",arch) | eval my_splunk_server = splunk_server | fields connectionType sourceIp sourceHost sourcePort destPort kb tcp_eps tcp_Kprocessed tcp_KBps my_splunk_server build version os arch guid |  eval lastReceived = if(kb>0, _time, null) | stats first(sourceIp) as sourceIp first(connectionType) as connectionType first(sourcePort) as sourcePort first(build) as build first(version) as version first(os) as os first(arch) as arch max(_time) as lastConnected max(lastReceived) as lastReceived sum(kb) as kb avg(tcp_eps) as avg_eps by sourceHost guid"
splunkmonitoring,"search index=""summary_indexers"" | eval _time = _time + 1800 | stats max(_time) as _time sum(kb) as KB first(avg_age) as avg_age first(parseQ_percentage) as parseQ_percentage first(indexQ_percentage) as indexQ_percentage by my_splunk_server |rename my_splunk_server as splunk_server | join type=outer splunk_server [search earliest=-30m latest=now  search index=""_internal"" source=""*metrics.log"" group=per_index_thruput series!=""_*"" | stats max(_time) as time1 sum(kb) as kb by splunk_server | join type=""outer"" splunk_server [ search earliest=-30m latest=now    search index=""_internal"" source=""*metrics.log"" group=queue name=parsingqueue | chart perc95(current_size_kb) as p95sz, max(max_size_kb) as maxsz by splunk_server | eval percentage=p95sz*100/maxsz | rename percentage as parseQ_percentage | appendcols [search  search index=""_internal"" source=""*metrics.log"" group=queue name=indexqueue | chart perc95(current_size_kb) as p95sz, max(max_size_kb) as maxsz by splunk_server | eval percentage=p95sz*100/maxsz | rename percentage as indexQ_percentage] | appendcols [search  search index=_internal group=per_sourcetype_thruput series=access_* | eval latency=avg_age*ev | stats sum(latency) as latency sum(ev) as events by splunk_server | fillnull latency events | eval avg_age=latency/events | fields avg_age] | fields splunk_server avg_age parseQ_percentage indexQ_percentage | fillnull avg_age] | addinfo |eval mystatus = if(kb==0, ""idle"", if(parseQ_percentage>50, ""overloaded"", if(indexQ_percentage>50,""overloaded"",""normal"")))] | eval _time = if(time1>_time, time1, _time) | addinfo | eval status = if(isnull(mystatus), ""dead"",mystatus)"
splunkmonitoring,"search index=""_internal"" source=""*metrics.log"" group=per_index_thruput series!=""_*"" | stats sum(kb) as kb by splunk_server | join type=""outer"" splunk_server [ search   search index=""_internal"" source=""*metrics.log"" group=queue name=parsingqueue | chart perc95(current_size_kb) as p95sz, max(max_size_kb) as maxsz by splunk_server | eval percentage=p95sz*100/maxsz | rename percentage as parseQ_percentage | appendcols [search  search index=""_internal"" source=""*metrics.log"" group=queue name=indexqueue | chart perc95(current_size_kb) as p95sz, max(max_size_kb) as maxsz by splunk_server | eval percentage=p95sz*100/maxsz | rename percentage as indexQ_percentage] | appendcols [search  search index=_internal group=per_sourcetype_thruput series=access_* | eval latency=avg_age*ev | stats sum(latency) as latency sum(ev) as events by splunk_server | fillnull latency events | eval avg_age=latency/events | fields avg_age] | fields splunk_server avg_age parseQ_percentage indexQ_percentage | fillnull avg_age] | rename splunk_server as my_splunk_server"
splunkmonitoring,"search index=""summary_indexers"" | eval mb=kb/1024 | eval _time = _time+1800 | rename my_splunk_server as splunk_server | timechart partial=f sum(mb) as MB by splunk_server"
splunkmonitoring,"search index=""_internal"" source=""*metrics.log"" group=queue name=parsingqueue | timechart partial=f eval(perc95(current_size)*100/max(max_size)) by splunk_server"
splunkmonitoring,"search index=""_internal"" source=""*metrics.log"" group=""per_index_thruput"" | stats sum(kb) as kb"
splunkmonitoring,"search index=""_internal"" source=""*license_usage.log"" | rename _time as lastReceived s as source st as mysourcetype h as host b as bytes o as originator | eval my_splunk_server = splunk_server | fields lastReceived source mysourcetype host bytes pool originator my_splunk_server | stats max(lastReceived) as lastReceived sum(bytes) as bytes by mysourcetype | append [search index=""summary_sourcetypes"" | eval _time = _time + 1800 | rename my_sourcetype as mysourcetype bytes_today as summary_idx_bytes_today] | stats max(lastReceived) as lastReceived first(bytes) as bytes by mysourcetype | eval lastConnected=lastReceived | eval bytes_today=bytes+summary_idx_bytes_today | addinfo | eval status = if(isnull(bytes) or lastConnected<(info_max_time-900),""missing"",""active"")  | search status=""missing"" | sort -lastReceived | fields lastReceived mysourcetype bytes status | rename lastReceived as ""Last Connected"" mysourcetype as ""Sourcetype"" bytes as ""Bytes"" status as ""Status"" | fieldformat ""Last Connected""=strftime('Last Connected', ""%D %H:%M:%S %p"")"
splunkmonitoring,"search index=""_internal"" source=""*license_usage.log"" | rename _time as lastReceived s as source st as mysourcetype h as host b as bytes o as originator | eval my_splunk_server = splunk_server | fields lastReceived source mysourcetype host bytes pool originator my_splunk_server | stats max(lastReceived) as lastReceived sum(bytes) as bytes by mysourcetype | append [search index=""summary_sourcetypes"" | eval _time = _time + 1800 | rename my_sourcetype as mysourcetype bytes_today as summary_idx_bytes_today] | stats max(lastReceived) as lastReceived first(bytes) as bytes by mysourcetype | eval lastConnected=lastReceived | eval bytes_today=bytes+summary_idx_bytes_today | addinfo | eval status = if(isnull(bytes) or lastConnected<(info_max_time-900),""missing"",""active"")"
splunkmonitoring,"search index=""_internal"" source=""*license_usage.log"" | rename _time as lastReceived s as source st as mysourcetype h as host b as bytes o as originator | eval my_splunk_server = splunk_server | fields lastReceived source mysourcetype host bytes pool originator my_splunk_server | fillnull bytes | stats sum(bytes) as bytes max(lastReceived) as lastReceived by mysourcetype |  appendcols [search earliest=@d  search index=""_internal"" source=""*license_usage.log"" | rename _time as lastReceived s as source st as mysourcetype h as host b as bytes o as originator | eval my_splunk_server = splunk_server | fields lastReceived source mysourcetype host bytes pool originator my_splunk_server | stats max(lastReceived) as lastReceived sum(bytes) as bytes by mysourcetype | append [search index=""summary_sourcetypes"" | eval _time = _time + 1800 | rename my_sourcetype as mysourcetype bytes_today as summary_idx_bytes_today] | stats max(lastReceived) as lastReceived first(bytes) as bytes by mysourcetype | eval lastConnected=lastReceived | eval bytes_today=bytes+summary_idx_bytes_today | addinfo | eval status = if(isnull(bytes) or lastConnected<(info_max_time-900),""missing"",""active"") | stats sum(bytes) as bytes_today by mysourcetype | fields bytes_today] | where isnotnull(mysourcetype) |  rename mysourcetype as my_sourcetype"
splunkmonitoring,"search index=""_internal"" source=""*license_usage.log"" | rename _time as lastReceived s as source st as mysourcetype h as host b as bytes o as originator | eval my_splunk_server = splunk_server | fields lastReceived source mysourcetype host bytes pool originator my_splunk_server  | stats avg(bytes) as avg_bytes_today by mysourcetype  | join mysourcetype type=outer [search earliest=-169h@h latest=-168h@h  search index=""_internal"" source=""*license_usage.log"" | rename _time as lastReceived s as source st as mysourcetype h as host b as bytes o as originator | eval my_splunk_server = splunk_server | fields lastReceived source mysourcetype host bytes pool originator my_splunk_server| stats avg(bytes) as avg_bytes_last_week by mysourcetype] | fillnull avg_bytes_today avg_bytes_last_week | eval avg_bytes_today=round(avg_bytes_today) | eval avg_bytes_last_week=round(avg_bytes_last_week) | appendcols [search  search earliest=-1h@h latest=now  search index=""_internal"" source=""*metrics.log"" group=per_index_thruput series!=""_*"" | stats avg(kb) as indexer_avg_kb_today | join splunk_server type=outer [search earliest=-169h@h latest=-168h@h  search index=""_internal"" source=""*metrics.log"" group=per_index_thruput series!=""_*""| stats avg(kb) as indexer_avg_kb_last_week count | fillnull indexer_avg_kb_last_week | fields indexer_avg_kb_last_week] | fillnull indexer_avg_kb_today | eval indexer_ratio=indexer_avg_kb_today/indexer_avg_kb_last_week | fields indexer_ratio] | streamstats first(indexer_ratio) as indexer_ratio |  where indexer_ratio*.5*avg_bytes_last_week > avg_bytes_today | eval bytes_diff = abs(avg_bytes_last_week - avg_bytes_today) | eval bytes_diff_perc = round(100*bytes_diff/avg_bytes_last_week, 4) | fields mysourcetype avg_bytes_last_week avg_bytes_today bytes_diff bytes_diff_perc | rename mysourcetype as ""Sourcetype"" avg_bytes_last_week as ""Average Bytes Last Week"" avg_bytes_today as ""Average Bytes Today"" bytes_diff as ""Bytes Difference from Last Week"" bytes_diff_perc as ""Percentage Difference"""
splunkmonitoring,"search index=""_internal"" source=""*license_usage.log"" | rename _time as lastReceived s as source st as mysourcetype h as host b as bytes o as originator | eval my_splunk_server = splunk_server | fields lastReceived source mysourcetype host bytes pool originator my_splunk_server  | stats avg(bytes) as avg_bytes_today by mysourcetype  | join mysourcetype type=outer [search earliest=-169h@h latest=-168h@h  search index=""_internal"" source=""*license_usage.log"" | rename _time as lastReceived s as source st as mysourcetype h as host b as bytes o as originator | eval my_splunk_server = splunk_server | fields lastReceived source mysourcetype host bytes pool originator my_splunk_server| stats avg(bytes) as avg_bytes_last_week by mysourcetype] | fillnull avg_bytes_today avg_bytes_last_week | eval avg_bytes_today=round(avg_bytes_today) | eval avg_bytes_last_week=round(avg_bytes_last_week) | appendcols [search  search earliest=-1h@h latest=now  search index=""_internal"" source=""*metrics.log"" group=per_index_thruput series!=""_*"" | stats avg(kb) as indexer_avg_kb_today | join splunk_server type=outer [search earliest=-169h@h latest=-168h@h  search index=""_internal"" source=""*metrics.log"" group=per_index_thruput series!=""_*""| stats avg(kb) as indexer_avg_kb_last_week count | fillnull indexer_avg_kb_last_week | fields indexer_avg_kb_last_week] | fillnull indexer_avg_kb_today | eval indexer_ratio=indexer_avg_kb_today/indexer_avg_kb_last_week | fields indexer_ratio] | streamstats first(indexer_ratio) as indexer_ratio |  where indexer_ratio*avg_bytes_last_week < 0.5*avg_bytes_today | eval bytes_diff = abs(avg_bytes_last_week - avg_bytes_today) | eval bytes_diff_perc = round(100*bytes_diff/avg_bytes_last_week, 4) | fields mysourcetype avg_bytes_last_week avg_bytes_today bytes_diff bytes_diff_perc | rename mysourcetype as ""Sourcetype"" avg_bytes_last_week as ""Average Bytes Last Week"" avg_bytes_today as ""Average Bytes Today"" bytes_diff as ""Bytes Difference from Last Week"" bytes_diff_perc as ""Percentage Difference"""
splunkmonitoring,"search index=""summary_sourcetypes"" |  eval Mbytes = bytes/1048576 | eval _time = _time+1800 | rename my_sourcetype as mysourcetype | timechart partial=f sum(Mbytes) as Mbytes by mysourcetype"
splunkmonitoring,"search index=""summary_sourcetypes"" |  eval Mbytes = bytes/1048576 | eval _time = _time+1800 | rename my_sourcetype as mysourcetype | timechart partial=f span=30m avg(Mbytes) as Mbytes by mysourcetype | bin _time as _day span=d | streamstats sum(*) as * by _day"
splunkmonitoring,"search index=""_internal"" source=""*license_usage.log"" | rename _time as lastReceived s as source st as mysourcetype h as host b as bytes o as originator | eval my_splunk_server = splunk_server | fields lastReceived source mysourcetype host bytes pool originator my_splunk_server | stats sum(bytes) as bytes max(lastReceived) as lastReceived by source | fields source lastReceived bytes | stats max(lastReceived) as lastReceived sum(bytes) as bytes by source | append [search index=""summary_sources"" | eval _time = _time + 1800 | rename my_source as source] | stats max(lastReceived) as lastReceived first(bytes) as bytes by source"
splunkmonitoring,"search index=""_internal"" source=""*license_usage.log"" | rename _time as lastReceived s as source st as mysourcetype h as host b as bytes o as originator | eval my_splunk_server = splunk_server | fields lastReceived source mysourcetype host bytes pool originator my_splunk_server | fillnull bytes | stats sum(bytes) as bytes max(lastReceived) as lastReceived by source | rename source as my_source"
splunkmonitoring,"search index=""summary_sources"" |  eval Mbytes = bytes/1048576 | eval _time = _time+1800 | rename my_source as source | timechart partial=f sum(Mbytes) as Mbytes by source"
splunkmonitoring,"search index=""_internal"" source=""*license_usage.log"" | rename _time as lastReceived s as source st as mysourcetype h as host b as bytes o as originator | eval my_splunk_server = splunk_server | fields lastReceived source mysourcetype host bytes pool originator my_splunk_server | stats sum(bytes) as bytes max(lastReceived) as lastReceived by host | fields host bytes lastReceived | stats max(lastReceived) as lastReceived sum(bytes) as bytes by host | append [search index=""summary_hosts"" | eval _time = _time + 1800 | rename my_host as host] | stats max(lastReceived) as lastReceived first(bytes) as bytes by host"
splunkmonitoring,"search index=""_internal"" source=""*license_usage.log"" | rename _time as lastReceived s as source st as mysourcetype h as host b as bytes o as originator | eval my_splunk_server = splunk_server | fields lastReceived source mysourcetype host bytes pool originator my_splunk_server | fillnull bytes | stats sum(bytes) as bytes max(lastReceived) as lastReceived by host | rename host as my_host"
splunkmonitoring,"search index=""summary_hosts"" |  eval Mbytes = bytes/1048576 | eval _time = _time+1800 | rename my_host as host | timechart partial=f sum(Mbytes) as Mbytes by host"
splunkmonitoring,"search index=""_internal"" source=""*license_usage.log"" | rename _time as lastReceived s as source st as mysourcetype h as host b as bytes o as originator | eval my_splunk_server = splunk_server | fields lastReceived source mysourcetype host bytes pool originator my_splunk_server | stats sum(bytes) as bytes max(lastReceived) as lastReceived by pool | fields pool bytes lastReceived | stats max(lastReceived) as lastReceived sum(bytes) as bytes by pool | append [search index=""summary_pools"" | eval _time = _time + 1800 | rename my_pool as pool] | stats max(lastReceived) as lastReceived first(bytes) as bytes by pool"
splunkmonitoring,"search index=""_internal"" source=""*license_usage.log"" | rename _time as lastReceived s as source st as mysourcetype h as host b as bytes o as originator | eval my_splunk_server = splunk_server | fields lastReceived source mysourcetype host bytes pool originator my_splunk_server | fillnull bytes | stats sum(bytes) as bytes max(lastReceived) as lastReceived by pool | rename pool as my_pool"
splunkmonitoring,"search index=""summary_pools"" |  eval Mbytes = bytes/1048576 | eval _time = _time+1800 | rename my_pool as pool | timechart partial=f sum(Mbytes) as Mbytes by pool"
splunkmonitoring,"search index=""summary_forwarders"" | eval mb=kb/1024 | eval _time = _time+1800 | timechart partial=f sum(mb) as MB by sourceHost"
splunkmonitoring,"search index=""summary_forwarders"" | delete"
splunkmonitoring,"search index=""summary_indexers"" | delete"
splunkmonitoring,"search index=""summary_sources"" | delete"
splunkmonitoring,"search index=""summary_hosts"" | delete"
splunkmonitoring,"search index=""summary_pools"" | delete"
splunkmonitoring,"search index=""summary_sourcetypes"" | delete"
splunkmonitoring,"search index=""summary_indexers"" |  eval _time = _time+1800 |  eval gb=kb/1048576 | bucket _time as day span=d | stats sum(gb) as gb by day | stats max(gb) as peakdailyusage, avg(gb) as avgdailyusage | eval peakdailyusage=round(peakdailyusage,2) | eval avgdailyusage=round(avgdailyusage,2)"
splunkmonitoring,"search index=""summary_indexers"" |  eval _time = _time+1800 |  eval gb=kb/1048576 | bucket _time as day span=d | stats sum(gb) as gb by day | sort limit=5 -gb | stats avg(gb) as mytop5 | eval mytop5=round(mytop5,2)"
splunkmonitoring,"search index=""summary_indexers"" |  eval _time = _time+1800 | timechart partial=f span=1d sum(kb) as KB | eval marker=""this week"" | append [search index=""summary_indexers"" earliest=-1w@w latest=@w | timechart span=1d sum(kb) as KB | eval marker = ""prior week"" | eval _time = _time+86400*7+1800] | append [search index=""summary_indexers"" earliest=-2w@w latest=-1w@w | timechart span=1d sum(kb) as KB | eval marker = ""2 weeks ago"" | eval _time = _time+86400*7*2+1800] | append [search index=""summary_indexers"" earliest=-3w@w latest=-2w@w | timechart span=1d sum(kb) as KB | eval marker = ""3 weeks ago"" | eval _time = _time+86400*7*3+1800] | eval gb=KB/1048576 | timechart median(gb) by marker"
splunkmonitoring,"search index=""summary_indexers"" |  eval _time = _time+1800 |  bucket _time as day span=d | eval gb=kb/1048576 | stats sum(gb) as gb by my_splunk_server, day | eval gb=round(gb,2)"
splunkmonitoring,"search index=""summary_pools"" | eval _time = _time+1800 |  bucket _time as day span=d  | eval gb=bytes/1073741824  | stats sum(gb) as gb by my_pool, day | eval gb=round(gb,2)"
